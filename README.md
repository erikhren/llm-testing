# llm-testing

## Requirements
1. Install requirements (poetry or pip)
`pip install -r requirements.txt`

2. Install Ollama CLI & Server

🐧 Linux (Debian/Ubuntu)
`curl -fsSL https://ollama.com/install.sh | sh`

Sets it up to run as a background service:
`ollama serve`

`ollama run llama3`
