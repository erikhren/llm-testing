# llm-testing

## Requirements

1. Install Ollama CLI & Server

🐧 Linux (Debian/Ubuntu)
`curl -fsSL https://ollama.com/install.sh | sh`

Sets it up to run as a background service:
`ollama serve`

`ollama run llama3`
